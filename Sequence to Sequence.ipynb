{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A basic sequence-to-sequence model, as introduced in Cho et al., 2014 (pdf), \n",
    "#consists of two recurrent neural networks (RNNs): an encoder that processes the input \n",
    "#and a decoder that generates the output. \n",
    "\n",
    "#Every Seq2seq model has 2 primary layers : the encoder and the decoder. \n",
    "#Generally, the encoder encodes the input sequence to an internal representation called 'context vector' \n",
    "#which is used by the decoder to generate the output sequence. \n",
    "#The lengths of input and output sequences can be different, as there is no explicit one on one relation between \n",
    "#the input and output sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An implementation of sequence to sequence learning for performing addition\\nInput: \"535+61\"\\nOutput: \"596\"\\nPadding is handled by using a repeated sentinel character (space)\\nInput may optionally be inverted, shown to increase performance in many tasks in:\\n\"Learning to Execute\"\\nhttp://arxiv.org/abs/1410.4615\\nand\\n\"Sequence to Sequence Learning with Neural Networks\"\\nhttp://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\\nTheoretically it introduces shorter term dependencies between source and target.\\nTwo digits inverted:\\n+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\\nThree digits inverted:\\n+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\\nFour digits inverted:\\n+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\\nFive digits inverted:\\n+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''An implementation of sequence to sequence learning for performing addition\n",
    "Input: \"535+61\"\n",
    "Output: \"596\"\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "Input may optionally be inverted, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "Two digits inverted:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "Three digits inverted:\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "Four digits inverted:\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "Five digits inverted:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.engine.training import slice_X\n",
    "from keras.layers import Activation, TimeDistributed, Dense, RepeatVector, recurrent\n",
    "import numpy as np\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    '''\n",
    "    Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    '''\n",
    "    def __init__(self, chars, maxlen):\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def encode(self, C, maxlen=None):\n",
    "        maxlen = maxlen if maxlen else self.maxlen\n",
    "        X = np.zeros((maxlen, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            X[i, self.char_indices[c]] = 1\n",
    "        return X\n",
    "\n",
    "    def decode(self, X, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            X = X.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for the model and dataset\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "INVERT = True\n",
    "# Try replacing GRU, or SimpleRNN\n",
    "RNN = recurrent.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars, MAXLEN)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n",
      "CPU times: user 5.81 s, sys: 0 ns, total: 5.81 s\n",
      "Wall time: 5.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Generating random  numbers to perofrm addition on\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789')) for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that X+Y == Y+X (hence the sorting)\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if INVERT:\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))\n",
    "\n",
    "#We now have 50000 examples of addition, each exaple contains the addition between two numbers\n",
    "#Each example contains the first number followed by '+' operand followed by the second number \n",
    "#examples - 85+96, 353+551, 6+936\n",
    "#The answers to the additon operation are stored in expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "CPU times: user 304 ms, sys: 8 ms, total: 312 ms\n",
      "Wall time: 309 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/keras/engine/training.py:301: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  return X[start:stop]\n",
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:34: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#The above questions and answers are going to be one hot encoded, before training.\n",
    "#The encoded values will be used to train the model\n",
    "#The maximum length of a question can be 7 (3 digits followed by '+' followed by 3 digits)\n",
    "#The maximum length of an answer can be 4 (Since the addition of 3 digits yields either a 3 digit number or a 4\n",
    "#4 digit number)\n",
    "\n",
    "#Now for training each number or operand is going to be one hot encode below\n",
    "#In one hot encode there are 12 possibilities '0123456789+ ' (The last one is a space)\n",
    "#Since we assume a maximum of 3 digit numbers, a two digit number is taken as space with two digts, or \n",
    "#a single digit number as two spaces with a number\n",
    "\n",
    "#So for questions we get 7 rows since the max possible length is 7, and each row has a length of 12 because it will\n",
    "#be one hot encoded with True and False, depending on the character(any one of the number, '+' operand, or space)\n",
    "#will be stored  in X_train and X_val\n",
    "#The 4th position in(1,2,3,4,5,6,7) will indicate the one hot encoding of the '+' operand\n",
    "\n",
    "##So for questions we get 4 rows since the max possible length is 4, and each row has a length of 12 because it will\n",
    "#be one hot encoded with True and False, depending on the character(any one of the number, '+' operand, or space)\n",
    "#will be stored  in y_train and y_val\n",
    "\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    X[i] = ctable.encode(sentence, maxlen=MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, maxlen=DIGITS + 1)\n",
    "\n",
    "# Shuffle (X, y) in unison as the later parts of X will almost all be larger digits\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over\n",
    "split_at = len(X) - len(X) / 10\n",
    "(X_train, X_val) = (slice_X(X, 0, split_at), slice_X(X, split_at))\n",
    "(y_train, y_val) = (y[:split_at], y[split_at:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "CPU times: user 328 ms, sys: 488 ms, total: 816 ms\n",
      "Wall time: 231 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Training the model with the encoded inputs\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE\n",
    "# note: in a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, nb_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "# For the decoder's input, we repeat the encoded input for each time step\n",
    "model.add(RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer\n",
    "for _ in range(LAYERS):\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# For each of step of the output sequence, decide which character should be chosen\n",
    "model.add(TimeDistributed(Dense(len(chars))))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 69s - loss: 1.8490 - acc: 0.3324 - val_loss: 1.7175 - val_acc: 0.3651\n",
      "Test score: 1.71748837605\n",
      "Test accuracy: 0.36515\n",
      "\n",
      "\n",
      "CPU times: user 1min 52s, sys: 2min 49s, total: 4min 41s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model each generation and show predictions against the validation dataset\n",
    "for iteration in range(1, 2):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(X_train, y_train, batch_size=BATCH_SIZE, nb_epoch=1,\n",
    "              validation_data=(X_val, y_val))\n",
    "    \n",
    "    score = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print('\\n')\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q 939+39 \n",
      "T 978 \n",
      "\u001b[91m☒\u001b[0m 104 \n",
      "---\n",
      "Q 686+56 \n",
      "T 742 \n",
      "\u001b[91m☒\u001b[0m 106 \n",
      "---\n",
      "Q 627+857\n",
      "T 1484\n",
      "\u001b[91m☒\u001b[0m 1135\n",
      "---\n",
      "Q 36+389 \n",
      "T 425 \n",
      "\u001b[91m☒\u001b[0m 344 \n",
      "---\n",
      "Q 17+653 \n",
      "T 670 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 180+116\n",
      "T 296 \n",
      "\u001b[91m☒\u001b[0m 103 \n",
      "---\n",
      "Q 507+732\n",
      "T 1239\n",
      "\u001b[91m☒\u001b[0m 103 \n",
      "---\n",
      "Q 51+614 \n",
      "T 665 \n",
      "\u001b[92m☑\u001b[0m 665 \n",
      "---\n",
      "Q 62+565 \n",
      "T 627 \n",
      "\u001b[91m☒\u001b[0m 666 \n",
      "---\n",
      "Q 6+936  \n",
      "T 942 \n",
      "\u001b[91m☒\u001b[0m 904 \n",
      "---\n",
      "CPU times: user 1.08 s, sys: 196 ms, total: 1.28 s\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#For predicting the outputs, the predict method will return an one hot encoded ouput, we decode the one hot encoded \n",
    "#ouptut to get our final output\n",
    "\n",
    "# Select 10 samples from the validation set at random so we can visualize errors\n",
    "for i in range(10):\n",
    "    ind = np.random.randint(0, len(X_val))\n",
    "    rowX, rowy = X_val[np.array([ind])], y_val[np.array([ind])]\n",
    "    preds = model.predict_classes(rowX, verbose=0)\n",
    "    q = ctable.decode(rowX[0])\n",
    "    correct = ctable.decode(rowy[0])\n",
    "    guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "    print('Q', q[::-1] if INVERT else q)\n",
    "    print('T', correct)\n",
    "    print(colors.ok + '☑' + colors.close if correct == guess else colors.fail + '☒' + colors.close, guess)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
